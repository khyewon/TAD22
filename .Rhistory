require(quanteda)
txt <- c(sent1 = "This is an example of the summary method for character objects.",
sent2 = "The cat in the hat swung the bat.")
summary(txt)
summary(corpus(data_char_ukimmig2010))
nsyllable(c("Superman.", "supercalifragilisticexpialidocious", "The cat in the hat."))
#To access the **syllables** of a text, we use `syllables()`:
?nsyllable
#To access the **syllables** of a text, we use `syllables()`:
??nsyllable
nsyllable(c("Superman.", "supercalifragilisticexpialidocious", "The cat in the hat."))
quanteda::nsyllable(c("Superman.", "supercalifragilisticexpialidocious", "The cat in the hat."))
require(quanteda)
nscrabble(c("cat", "quixotry", "zoo"))
quanteda::nscrabble(c("cat", "quixotry", "zoo"))
#We can analyze the **lexical diversity** of texts, using `lexdiv()` on a dfm:
summary(data_corpus_inaugural)
myDfm <- dfm(corpus_subset(data_corpus_inaugural, Year > 1980))
textstat_lexdiv(myDfm, "R")
textstat_readability(myDfm, "R")
install.packages("quanteda.textstats")
require(quanteda.textstats)
#To access the **syllables** of a text, we use `syllables()`:
nsyllable(c("Superman.", "supercalifragilisticexpialidocious", "The cat in the hat."))
#To access the **syllables** of a text, we use `syllables()`:
quanteda.textstats::nsyllable(c("Superman.", "supercalifragilisticexpialidocious", "The cat in the hat."))
textstat_readability(myDfm, "R")
?textstat_readability
mycorpus <- (corpus_subset(data_corpus_inaugural, Year > 1980))
textstat_readability(mycorpus, "R")
textstat_readability(mycorpus)
readab <- textstat_readability(corpus_subset(data_corpus_inaugural, Year > 1980),
measure = "Flesch.Kincaid")
readab
## Presidential Inaugural Address Corpus
presDfm <- dfm(data_corpus_inaugural, remove = stopwords("english"))
#We can **identify documents and terms that are similar to one another**, using `similarity()`:
?dfm
stopwords("english")
# compute some document similarities
textstat_simil(presDfm, "1985-Reagan",  margin = "documents")
?textstat_simil
# compute some document similarities
textstat_simil(presDfm, presDfm["1985-Reagan"],  margin = "documents")
# compute some document similarities
textstat_simil(presDfm, presDfm["1985-Reagan",],  margin = "documents")
textstat_simil(presDfm, c("2009-Obama", "2013-Obama"), margin = "documents", method = "cosine")
textstat_simil(presDfm, presDfm[c("2009-Obama", "2013-Obama"),], margin = "documents", method = "cosine")
presDfm <- dfm(corpus_subset(data_corpus_inaugural, Year > 1900), stem = TRUE,
remove = stopwords("english"))
presDfm <- dfm_trim(presDfm, min_count = 5, min_docfreq = 3)
presDistMat <- dist(as.matrix(dfm_weight(presDfm, "relFreq")))
dfm_weight(presDfm, "relFreq")
?dfm_weight
dfm_weight(presDfm, "prop")
as.matrix(dfm_weight(presDfm, "prop"))
presDistMat <- dist(as.matrix(dfm_weight(presDfm, "prop")))
# hiarchical clustering the distance object
presCluster <- hclust(presDistMat)
# label with document names
presCluster$labels <- docnames(presDfm)
plot(presCluster)
txt <- c(sent1 = "This is an example of the summary method for character objects.",
sent2 = "The cat in the hat swung the bat.")
corpus_txt<-corpus(txt)
corpus_txt
dfm_txt<-dfm(corpus_txt)
##load in data
data("data_corpus_inaugural")
df <- texts(data_corpus_inaugural)
data_corpus_inaugural
df <- as.character(data_corpus_inaugural)
df[1]
toks <- tokens(data_corpus_inaugural)
toks
tokenz <- lengths(toks)
tokenz
# typez <- lapply(lapply(tokens,  unique ), length)
typez <- ntype(df)
df
# typez <- lapply(lapply(tokens,  unique ), length)
typez <- ntype(df)
ttr <- typez / tokenz
ttr
library(quanteda)
txt <- c(sent1 = "This is an example of the summary method for character objects.",
sent2 = "The cat in the hat swung the bat.")
corpus_txt<-corpus(txt)
dfm_txt<-dfm(corpus_txt)
##load in data
data("data_corpus_inaugural")
df <- texts(data_corpus_inaugural)
df[1]
## Lexical diversity measures
# TTR
toks <- tokens(data_corpus_inaugural)
tokenz <- lengths(toks)
tokenz
# typez <- lapply(lapply(tokens,  unique ), length)
typez <- ntype(df)
ttr <- typez / tokenz
##basic plot
plot(ttr)
docvars(data_corpus_inaugural)$Party
aggregate(ttr, by = list(docvars(data_corpus_inaugural)$Party), FUN = mean)
# another way:
textstat_lexdiv(dfm(data_corpus_inaugural, groups = "President", verbose = FALSE))
library(quanteda.textstats)
# another way:
textstat_lexdiv(dfm(data_corpus_inaugural, groups = "President", verbose = FALSE))
data_corpus_inaugural
# another way:
textstat_lexdiv((data_corpus_inaugural, groups = "President", verbose = FALSE))
# another way:
textstat_lexdiv(data_corpus_inaugural, groups = "President", verbose = FALSE)
##let's look at FRE
textstat_readability(data_corpus_inaugural, "Flesch")
corr_matrix<-textstat_readability(data_corpus_inaugural, c("Flesch", "Dale.Chall", "SMOG", "Coleman.Liau" ))
corr_matrix_nums<- corr_matrix[,c(2:5)]
cor(corr_matrix_nums)
require(quanteda.textstats)
